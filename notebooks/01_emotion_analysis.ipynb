{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494b6c4-690d-4422-beda-7b0115f4ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4e6cc-a814-4562-a060-5ef06e5e1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install shap datasets\n",
    "!pip install huggingface_hub[hf_xet]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf250d-cc93-46d1-943d-2760adb3879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shap\n",
    "import torch\n",
    "import requests\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d55823-2c9c-40b9-93a8-6c25f431eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Loading and Exploring the GoEmotions Dataset\n",
    "# We load the GoEmotions dataset (`train.tsv`) and map label IDs to their corresponding emotion names using the `emotions.txt` file.\n",
    "\n",
    "response = requests.get(\"https://raw.githubusercontent.com/Hadia-Eshan/politics_of_emotion/main/data/emotions.txt\")\n",
    "emotions = [line.strip() for line in response.text.split('\\n') if line.strip()]\n",
    "id2emotion = {i: emotion for i, emotion in enumerate(emotions)}\n",
    "train_df = pd.read_csv('https://raw.githubusercontent.com/Hadia-Eshan/politics_of_emotion/main/data/train.tsv', sep='\\t', header=None, names=['text', 'label', 'id'])\n",
    "\n",
    "# Drop bad rows (only keep if label is digits or comma-separated digits)\n",
    "train_df = train_df[train_df['label'].astype(str).str.match(r'^\\d+(,\\d+)*$', na=False)].copy()\n",
    "\n",
    "# Map label(s) to emotion names\n",
    "def map_labels(label_str):\n",
    "    ids = list(map(int, label_str.split(',')))\n",
    "    return [id2emotion[i] for i in ids]\n",
    "train_df['emotion_names'] = train_df['label'].apply(map_labels)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd837d0-70f3-46f5-94d3-8f980f54e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Emotion Frequency Distribution\n",
    "#This section visualizes how often each emotion label appears in the GoEmotions dataset, providing insight into label imbalance or dominance.\n",
    "\n",
    "\n",
    "# emotion names into one list\n",
    "all_emotions = [emotion for sublist in train_df['emotion_names'] for emotion in sublist]\n",
    "emotion_counts = Counter(all_emotions)\n",
    "emotion_freq_df = pd.DataFrame(emotion_counts.items(), columns=['emotion', 'count'])\n",
    "emotion_freq_df = emotion_freq_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(emotion_freq_df['emotion'], emotion_freq_df['count'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Emotion Frequency in GoEmotions Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7f1b1-3215-4003-9eb5-83a4b4a15ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Sentiment Category Breakdown\n",
    "# Using the provided `sentiment_dict.json`, we group emotions into broader categories (positive, negative, ambiguous) and visualize their distribution with a pie chart.\n",
    "\n",
    "response = json.loads(requests.get(\"https://raw.githubusercontent.com/Hadia-Eshan/politics_of_emotion/main/data/sentiment_dict.json\").text)\n",
    "\n",
    "# Build emotion â†’ sentiment mapping\n",
    "emotion_to_sentiment = {}\n",
    "for sentiment, emotion_list in sentiment_dict.items():\n",
    "    for emo in emotion_list:\n",
    "        emotion_to_sentiment[emo] = sentiment\n",
    "sentiment_counts = defaultdict(int)\n",
    "\n",
    "for emotion_list in train_df['emotion_names']:\n",
    "    for emo in emotion_list:\n",
    "        sentiment = emotion_to_sentiment.get(emo, 'unknown')\n",
    "        sentiment_counts[sentiment] += 1\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sentiment_counts.values(), labels=sentiment_counts.keys(), autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Sentiment Distribution in GoEmotions Dataset\")\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d3009-a21f-4b6e-90f7-bded68a82cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Emotion Co-occurrence Heatmap\n",
    "# We analyze how emotions tend to co-occur within the same text by generating a symmetric co-occurrence matrix and plotting it as a heatmap.\n",
    "\n",
    "\n",
    "co_matrix = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# 2. Count co-occurring emotion pairs\n",
    "for emo_list in train_df['emotion_names']:\n",
    "    if len(emo_list) > 1:\n",
    "        for e1, e2 in itertools.combinations(sorted(emo_list), 2):\n",
    "            co_matrix[e1][e2] += 1\n",
    "            co_matrix[e2][e1] += 1  # symmetric\n",
    "co_df = pd.DataFrame(co_matrix).fillna(0)\n",
    "\n",
    "# reorder for better visual\n",
    "co_df = co_df.loc[sorted(co_df.index), sorted(co_df.columns)]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(co_df, cmap='Blues', linewidths=0.5)\n",
    "plt.title(\"Emotion Co-occurrence Heatmap\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabbd75-2ee2-4d72-bde4-2877f84b49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Single vs. Multi-Emotion Comment Examples\n",
    "# We display examples of comments with a single emotion label and those with multiple labels to understand the variability in emotional richness.\n",
    "\n",
    "\n",
    "train_df['emotion_count'] = train_df['emotion_names'].apply(len)\n",
    "\n",
    "# Comments with exactly 1 emotion\n",
    "one_emotion = train_df[train_df['emotion_count'] == 1].sample(5, random_state=1)\n",
    "\n",
    "# Comments with 3 or more emotions\n",
    "multi_emotion = train_df[train_df['emotion_count'] >= 3].sample(5, random_state=2)\n",
    "\n",
    "# 4. low-emotion\n",
    "print(\"Low-emotion comments (1 label):\\n\")\n",
    "for i, row in one_emotion.iterrows():\n",
    "    print(f\"- {row['emotion_names'][0].upper()}: {row['text']}\\n\")\n",
    "\n",
    "# 5. high-emotion\n",
    "print(\"\\nHigh-emotion comments (3+ labels):\\n\")\n",
    "for i, row in multi_emotion.iterrows():\n",
    "    print(f\"- {', '.join(row['emotion_names']).upper()}: {row['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149f4a6-2757-43b3-a5c0-edae170af2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "6. Load Pre-trained Emotion Classification Model\n",
    "We load a transformer model fine-tuned on GoEmotions to perform multi-label emotion classification \n",
    "on political texts.\n",
    "'''\n",
    "\n",
    "# Using DistilBERT model fine-tuned on GoEmotions\n",
    "model_name = \"joeddav/distilbert-base-uncased-go-emotions-student\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Creates a multi-label classifier that returns all relevant emotion scores\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, top_k=None, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280abff-15d5-457f-b3f2-a57d7c7c5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Demo: Emotion Prediction on Sample Political Texts\n",
    "\n",
    "def classify_emotions(data, classifier, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Takes a list of dicts with 'text', 'topic', and 'group', \n",
    "    returns a DataFrame with predicted emotions and metadata.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for item in data:\n",
    "        preds = classifier(item['text'])[0]\n",
    "        top_preds = [p for p in preds if p['score'] > threshold]\n",
    "        results.append({\n",
    "            'text': item['text'],\n",
    "            'topic': item['topic'],\n",
    "            'group': item['group'],\n",
    "            'emotions': [p['label'] for p in top_preds],\n",
    "            'scores': [round(p['score'], 2) for p in top_preds]\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179b1c1-446b-43e5-8e5f-6a85df434936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "political_texts = [\n",
    "    {\"text\": \"We will defend democracy and protect the rights of every citizen.\", \"topic\": \"Democracy\", \"group\": \"Group A\"},\n",
    "    {\"text\": \"Their reckless spending has put our country in danger.\", \"topic\": \"Economy\", \"group\": \"Group B\"},\n",
    "    {\"text\": \"We are proud of the progress we've made in healthcare.\", \"topic\": \"Healthcare\", \"group\": \"Group A\"},\n",
    "    {\"text\": \"They continue to spread fear and misinformation.\", \"topic\": \"Disinformation\", \"group\": \"Group B\"},\n",
    "    {\"text\": \"Justice will prevail, and the people will be heard.\", \"topic\": \"Justice\", \"group\": \"Group A\"},\n",
    "    \n",
    "    {\"text\": \"This administration has failed our economy time and again.\", \"topic\": \"Economy\", \"group\": \"Group B\"},\n",
    "    {\"text\": \"We stand united against corruption and inequality.\", \"topic\": \"Justice\", \"group\": \"Group A\"},\n",
    "    {\"text\": \"Their policies are built on lies and division.\", \"topic\": \"Disinformation\", \"group\": \"Group B\"},\n",
    "    {\"text\": \"Healthcare is a right, not a privilege.\", \"topic\": \"Healthcare\", \"group\": \"Group A\"},\n",
    "    {\"text\": \"They ignore science and continue to mislead the public.\", \"topic\": \"Disinformation\", \"group\": \"Group B\"},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "emotion_df = classify_emotions(political_texts, classifier)\n",
    "emotion_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f256d-9efc-44f6-80af-47507820ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 8. Emotion Frequency in Political Texts\n",
    "all_preds = [emotion for emolist in emotion_df['emotions'] for emotion in emolist]\n",
    "\n",
    "# Count emotion occurrences\n",
    "emotion_counts = Counter(all_preds)\n",
    "emotion_df_plot = pd.DataFrame(emotion_counts.items(), columns=['emotion', 'count'])\n",
    "emotion_df_plot = emotion_df_plot.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(emotion_df_plot['emotion'], emotion_df_plot['count'], color='skyblue')\n",
    "plt.title(\"Emotion Frequency in Political Texts\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ef2ad-6020-4e47-8aff-3a423fd9f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Emotion Heatmap by Topic\n",
    "\n",
    "# Expand the emotion list into one row per emotion\n",
    "exploded = emotion_df.explode('emotions')\n",
    "\n",
    "# Group by topic and emotion\n",
    "grouped = exploded.groupby(['topic', 'emotions']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot as heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(grouped, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title(\"Emotion Use by Topic\")\n",
    "plt.ylabel(\"Topic\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7450b1d-d13b-4a0d-b012-9118b3016db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Emotion Comparison Between Groups\n",
    "\n",
    "def count_emotions_from_df(df, group_name, threshold=0.1):\n",
    "    emotion_counter = Counter()\n",
    "    group_rows = df[df['group'] == group_name]\n",
    "    for _, row in group_rows.iterrows():\n",
    "        for emotion, score in zip(row['emotions'], row['scores']):\n",
    "            if score > threshold:\n",
    "                emotion_counter[emotion] += 1\n",
    "    return emotion_counter\n",
    "\n",
    "\n",
    "# Count for each group\n",
    "counter_a = count_emotions_from_df(emotion_df, \"Group A\")\n",
    "counter_b = count_emotions_from_df(emotion_df, \"Group B\")\n",
    "\n",
    "# Merge and plot\n",
    "all_emotions = sorted(set(counter_a) | set(counter_b))\n",
    "counts_a = [counter_a.get(e, 0) for e in all_emotions]\n",
    "counts_b = [counter_b.get(e, 0) for e in all_emotions]\n",
    "\n",
    "# Plot\n",
    "x = range(len(all_emotions))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, counts_a, width=0.4, label=\"Group A\", align='center')\n",
    "plt.bar([i + 0.4 for i in x], counts_b, width=0.4, label=\"Group B\", align='center')\n",
    "plt.xticks([i + 0.2 for i in x], all_emotions, rotation=45)\n",
    "plt.ylabel(\"Emotion Count\")\n",
    "plt.title(\"Emotion Usage Comparison by Group\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0e286-cf6c-4208-a0c1-5acccb17e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_with_emotions(sentence, model, tokenizer, classifier, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Displays attention heatmap + predicted emotions for a given sentence.\n",
    "    \n",
    "    Parameters:\n",
    "    - sentence (str): Political sentence to analyze\n",
    "    - model: transformer model\n",
    "    - tokenizer: associated tokenizer\n",
    "    - classifier: text-classification pipeline\n",
    "    - threshold (float): minimum score to include an emotion\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ—£ï¸ Sentence: {sentence}\\n\")\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True)\n",
    "    \n",
    "    # Predict emotions\n",
    "    preds = classifier(sentence)[0]\n",
    "    top_emotions = [p['label'].upper() for p in preds if p['score'] > threshold]\n",
    "    \n",
    "    # Attention output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "    attentions = outputs.attentions[-1]\n",
    "    attention_matrix = attentions[0, 0]\n",
    "    \n",
    "    # Tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_matrix, xticklabels=tokens, yticklabels=tokens, cmap=\"Reds\")\n",
    "    emotion_str = \", \".join(top_emotions) if top_emotions else \"No strong emotion\"\n",
    "    plt.title(f\"Attention Heatmap â€“ Final Layer, Head 1\\nPredicted Emotions: {emotion_str}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_attention_with_emotions(political_texts[3]['text'], model, tokenizer, classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199ea1b-d8f6-4cf4-a670-d1b6dab8b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_shap(sentence, classifier):\n",
    "    \"\"\"\n",
    "    Generate SHAP explanation for a given sentence using a text classification pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "        sentence (str): The input sentence to analyze.\n",
    "        classifier: HuggingFace pipeline object for text classification.\n",
    "    \"\"\"\n",
    "    # Predict emotions\n",
    "    preds = classifier(sentence)[0]\n",
    "    top_preds = [(p['label'], round(p['score'], 3)) for p in preds if p['score'] > 0.1]\n",
    "\n",
    "    # Initialize SHAP explainer\n",
    "    explainer = shap.Explainer(classifier, masker=shap.maskers.Text(tokenizer=classifier.tokenizer))\n",
    "    shap_values = explainer([sentence])\n",
    "\n",
    "    # Print sentence and predicted emotions\n",
    "    print(f\"\\nðŸ“Œ Text: {sentence}\")\n",
    "    print(\"ðŸŽ¯ Predicted Emotions:\")\n",
    "    for label, score in top_preds:\n",
    "        print(f\"   â†’ {label.upper()} ({score})\")\n",
    "\n",
    "    # Plot SHAP explanation\n",
    "    shap.plots.text(shap_values[0])\n",
    "    \n",
    "explain_with_shap(political_texts[3]['text'], classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11145f6-d413-4b78-8ca3-d94cfaf4e90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
